--- TMVAClassification       : Using input files: ./pp_tt_hadronic_14TeV500kEvtsGenCutT350_CutQCD350_InclusiveCut350_delphes_events.root and ./pp_QCD_14TeV500kEvtsGenCutQCD350_InclusiveCut350_delphes_events.root
DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree Delphes of type Signal with 500000 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree Delphes of type Background with 447443 events
Factory                  : Booking method: Likelihood
                         : 
Factory                  : Booking method: LikelihoodPCA
                         : 
LikelihoodPCA            : [dataset] : Create Transformation "PCA" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'mass' <---> Output : variable 'mass'
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : Booking method: KNN
                         : 
Factory                  : Booking method: LD
                         : 
                         : Rebuilding Dataset dataset
                         : Building event vectors for type 2 Signal
                         : Dataset[dataset] :  create input formulas for tree Delphes
                         : Building event vectors for type 2 Background
                         : Dataset[dataset] :  create input formulas for tree Delphes
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 225000
                         : Signal     -- testing events             : 275000
                         : Signal     -- training and testing events: 500000
                         : Background -- training events            : 225000
                         : Background -- testing events             : 222441
                         : Background -- training and testing events: 447441
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : ------------------------------------------------
                         :             mass    tau1    tau2    tau3    tau4
                         :    mass:  +1.000  +0.657  +0.616  +0.519  +0.445
                         :    tau1:  +0.657  +1.000  +0.799  +0.643  +0.614
                         :    tau2:  +0.616  +0.799  +1.000  +0.828  +0.766
                         :    tau3:  +0.519  +0.643  +0.828  +1.000  +0.939
                         :    tau4:  +0.445  +0.614  +0.766  +0.939  +1.000
                         : ------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : ------------------------------------------------
                         :             mass    tau1    tau2    tau3    tau4
                         :    mass:  +1.000  +0.827  +0.664  +0.615  +0.600
                         :    tau1:  +0.827  +1.000  +0.823  +0.778  +0.767
                         :    tau2:  +0.664  +0.823  +1.000  +0.951  +0.928
                         :    tau3:  +0.615  +0.778  +0.951  +1.000  +0.984
                         :    tau4:  +0.600  +0.767  +0.928  +0.984  +1.000
                         : ------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : Booking method: FDA_GA
                         : 
                         : Create parameter interval for parameter 0 : [-1,1]
                         : Create parameter interval for parameter 1 : [-10,10]
                         : Create parameter interval for parameter 2 : [-10,10]
                         : Create parameter interval for parameter 3 : [-10,10]
                         : Create parameter interval for parameter 4 : [-10,10]
                         : User-defined formula string       : "(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3"
                         : TFormula-compatible formula string: "[0]+[1]*[5]+[2]*[6]+[3]*[7]+[4]*[8]"
Factory                  : Booking method: MLPBNN
                         : 
MLPBNN                   : [dataset] : Create Transformation "N" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'mass' <---> Output : variable 'mass'
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
MLPBNN                   : Building Network. 
                         : Initializing weights
Factory                  : Booking method: DNN_CPU
                         : 
                         : Parsing option string: 
                         : ... "!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:WeightInitialization=XAVIERUNIFORM:Layout=TANH|128,TANH|128,TANH|128,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5:Architecture=CPU"
                         : The following options are set:
                         : - By User:
                         :     <none>
                         : - Default:
                         :     Boost_num: "0" [Number of times the classifier will be boosted]
                         : Parsing option string: 
                         : ... "!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:WeightInitialization=XAVIERUNIFORM:Layout=TANH|128,TANH|128,TANH|128,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5:Architecture=CPU"
                         : The following options are set:
                         : - By User:
                         :     V: "True" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
                         :     VarTransform: "N" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
                         :     H: "False" [Print method-specific help message]
                         :     Layout: "TANH|128,TANH|128,TANH|128,LINEAR" [Layout of the network.]
                         :     ErrorStrategy: "CROSSENTROPY" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]
                         :     WeightInitialization: "XAVIERUNIFORM" [Weight initialization strategy]
                         :     Architecture: "CPU" [Which architecture to perform the training on.]
                         :     TrainingStrategy: "LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5" [Defines the training strategies.]
                         : - Default:
                         :     VerbosityLevel: "Default" [Verbosity level]
                         :     CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
                         :     IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
                         :     InputLayout: "0|0|0" [The Layout of the input]
                         :     BatchLayout: "0|0|0" [The Layout of the batch]
                         :     RandomSeed: "0" [Random seed used for weight initialization and batch shuffling]
                         :     ValidationSize: "20%" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]
DNN_CPU                  : [dataset] : Create Transformation "N" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'mass' <---> Output : variable 'mass'
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
                         : Will now use the CPU architecture with BLAS and IMT support !
Factory                  : Booking method: BDT
                         : 
Factory                  : Booking method: RuleFit
                         : 
Factory                  : Train all methods
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'mass' <---> Output : variable 'mass'
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : [dataset] : Create Transformation "D" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'mass' <---> Output : variable 'mass'
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : [dataset] : Create Transformation "P" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'mass' <---> Output : variable 'mass'
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'mass' <---> Output : variable 'mass'
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : [dataset] : Create Transformation "D" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'mass' <---> Output : variable 'mass'
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:     131.53     64.098   [-1.5259e-05     993.83 ]
                         :     tau1:    0.16202   0.095592   [     0.0000    0.65185 ]
                         :     tau2:   0.082311   0.046960   [     0.0000    0.43728 ]
                         :     tau3:   0.053519   0.028178   [     0.0000    0.27865 ]
                         :     tau4:   0.042640   0.021375   [     0.0000    0.23027 ]
                         : -----------------------------------------------------------
                         : Preparing the Decorrelation transformation...
TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:     2.0517     1.0000   [-2.3847e-07     15.525 ]
                         :     tau1:   -0.12519     1.0000   [    -12.521     6.6249 ]
                         :     tau2:   0.095566     1.0000   [    -10.716     7.4088 ]
                         :     tau3:    0.50038     1.0000   [    -5.4503     12.092 ]
                         :     tau4:     1.3046     1.0000   [    -8.9816     10.160 ]
                         : -----------------------------------------------------------
                         : Preparing the Principle Component (PCA) transformation...
TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:-1.5688e-09     64.098   [    -131.53     862.30 ]
                         :     tau1: 2.9565e-13   0.065802   [   -0.98895    0.49233 ]
                         :     tau2:-3.7663e-15   0.029256   [   -0.20303    0.17156 ]
                         :     tau3:-3.3428e-13   0.013720   [  -0.098714   0.078671 ]
                         :     tau4:-9.5195e-14  0.0043883   [  -0.027854   0.064841 ]
                         : -----------------------------------------------------------
                         : Preparing the Gaussian transformation...
                         : Preparing the Decorrelation transformation...
TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:  0.0021749     1.0000   [    -4.2846     8.5532 ]
                         :     tau1:  0.0016493     1.0000   [    -3.3182     8.1693 ]
                         :     tau2:  0.0011861     1.0000   [    -5.0577     8.3562 ]
                         :     tau3:  0.0017481     1.0000   [    -4.4394     14.638 ]
                         :     tau4:  0.0017713     1.0000   [    -8.8084     9.8904 ]
                         : -----------------------------------------------------------
                         : Ranking input variables (method unspecific)...
IdTransformation         : Ranking result (top variable is best ranked)
                         : -----------------------------
                         : Rank : Variable  : Separation
                         : -----------------------------
                         :    1 : Mass      : 4.287e-01
                         :    2 : Tau1      : 2.915e-01
                         :    3 : Tau2      : 1.588e-01
                         :    4 : Tau4      : 6.290e-02
                         :    5 : Tau3      : 6.271e-02
                         : -----------------------------
Factory                  : Train method: Likelihood for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ Likelihood ] :
                         : 
                         : --- Short description:
                         : 
                         : The maximum-likelihood classifier models the data with probability 
                         : density functions (PDF) reproducing the signal and background
                         : distributions of the input variables. Correlations among the 
                         : variables are ignored.
                         : 
                         : --- Performance optimisation:
                         : 
                         : Required for good performance are decorrelated input variables
                         : (PCA transformation via the option "VarTransform=Decorrelate"
                         : may be tried). Irreducible non-linear correlations may be reduced
                         : by precombining strongly correlated input variables, or by simply
                         : removing one of the variables.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : High fidelity PDF estimates are mandatory, i.e., sufficient training 
                         : statistics is required to populate the tails of the distributions
                         : It would be a surprise if the default Spline or KDE kernel parameters
                         : provide a satisfying fit to the data. The user is advised to properly
                         : tune the events per bin and smooth options in the spline cases
                         : individually per variable. If the KDE kernel is used, the adaptive
                         : Gaussian kernel may lead to artefacts, so please always also try
                         : the non-adaptive one.
                         : 
                         : All tuning parameters must be adjusted individually for each input
                         : variable!
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
                         : Filling reference histograms
                         : Building PDF out of reference histograms
                         : Elapsed time for training with 450000 events: 2.24 sec         
Likelihood               : [dataset] : Evaluation of Likelihood on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.302 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_Likelihood.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_Likelihood.class.C
                         : TMVA.root:/dataset/Method_Likelihood/Likelihood
Factory                  : Training finished
                         : 
Factory                  : Train method: LikelihoodPCA for Classification
                         : 
                         : Preparing the Principle Component (PCA) transformation...
TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:-1.5688e-09     64.098   [    -131.53     862.30 ]
                         :     tau1: 2.9565e-13   0.065802   [   -0.98895    0.49233 ]
                         :     tau2:-3.7663e-15   0.029256   [   -0.20303    0.17156 ]
                         :     tau3:-3.3428e-13   0.013720   [  -0.098714   0.078671 ]
                         :     tau4:-9.5195e-14  0.0043883   [  -0.027854   0.064841 ]
                         : -----------------------------------------------------------
                         : Filling reference histograms
                         : Building PDF out of reference histograms
                         : Elapsed time for training with 450000 events: 2.67 sec         
LikelihoodPCA            : [dataset] : Evaluation of LikelihoodPCA on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.609 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_LikelihoodPCA.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_LikelihoodPCA.class.C
                         : TMVA.root:/dataset/Method_Likelihood/LikelihoodPCA
Factory                  : Training finished
                         : 
Factory                  : Train method: KNN for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ KNN ] :
                         : 
                         : --- Short description:
                         : 
                         : The k-nearest neighbor (k-NN) algorithm is a multi-dimensional classification
                         : and regression algorithm. Similarly to other TMVA algorithms, k-NN uses a set of
                         : training events for which a classification category/regression target is known. 
                         : The k-NN method compares a test event to all training events using a distance 
                         : function, which is an Euclidean distance in a space defined by the input variables. 
                         : The k-NN method, as implemented in TMVA, uses a kd-tree algorithm to perform a
                         : quick search for the k events with shortest distance to the test event. The method
                         : returns a fraction of signal events among the k neighbors. It is recommended
                         : that a histogram which stores the k-NN decision variable is binned with k+1 bins
                         : between 0 and 1.
                         : 
                         : --- Performance tuning via configuration options: 
                         : 
                         : The k-NN method estimates a density of signal and background events in a 
                         : neighborhood around the test event. The method assumes that the density of the 
                         : signal and background events is uniform and constant within the neighborhood. 
                         : k is an adjustable parameter and it determines an average size of the 
                         : neighborhood. Small k values (less than 10) are sensitive to statistical 
                         : fluctuations and large (greater than 100) values might not sufficiently capture  
                         : local differences between events in the training set. The speed of the k-NN
                         : method also increases with larger values of k. 
                         : 
                         : The k-NN method assigns equal weight to all input variables. Different scales 
                         : among the input variables is compensated using ScaleFrac parameter: the input 
                         : variables are scaled so that the widths for central ScaleFrac*100% events are 
                         : equal among all the input variables.
                         : 
                         : --- Additional configuration options: 
                         : 
                         : The method inclues an option to use a Gaussian kernel to smooth out the k-NN
                         : response. The kernel re-weights events using a distance to the test event.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
KNN                      : <Train> start...
                         : Reading 450000 events
                         : Number of signal events 225000
                         : Number of background events 225000
                         : Creating kd-tree with 450000 events
                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)
ModulekNN                : Optimizing tree for 5 variables with 450000 values
                         : <Fill> Class 1 has   225000 events
                         : <Fill> Class 2 has   225000 events
                         : Elapsed time for training with 450000 events: 0.906 sec         
KNN                      : [dataset] : Evaluation of KNN on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 116 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_KNN.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_KNN.class.C
Factory                  : Training finished
                         : 
Factory                  : Train method: LD for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ LD ] :
                         : 
                         : --- Short description:
                         : 
                         : Linear discriminants select events by distinguishing the mean 
                         : values of the signal and background distributions in a trans- 
                         : formed variable space where linear correlations are removed.
                         : The LD implementation here is equivalent to the "Fisher" discriminant
                         : for classification, but also provides linear regression.
                         : 
                         :    (More precisely: the "linear discriminator" determines
                         :     an axis in the (correlated) hyperspace of the input 
                         :     variables such that, when projecting the output classes 
                         :     (signal and background) upon this axis, they are pushed 
                         :     as far as possible away from each other, while events
                         :     of a same class are confined in a close vicinity. The  
                         :     linearity property of this classifier is reflected in the 
                         :     metric with which "far apart" and "close vicinity" are 
                         :     determined: the covariance matrix of the discriminating
                         :     variable space.)
                         : 
                         : --- Performance optimisation:
                         : 
                         : Optimal performance for the linear discriminant is obtained for 
                         : linearly correlated Gaussian-distributed variables. Any deviation
                         : from this ideal reduces the achievable separation power. In 
                         : particular, no discrimination at all is achieved for a variable
                         : that has the same sample mean for signal and background, even if 
                         : the shapes of the distributions are very different. Thus, the linear 
                         : discriminant often benefits from a suitable transformation of the 
                         : input variables. For example, if a variable x in [-1,1] has a 
                         : a parabolic signal distributions, and a uniform background
                         : distributions, their mean value is zero in both cases, leading 
                         : to no separation. The simple transformation x -> |x| renders this 
                         : variable powerful for the use in a linear discriminant.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : <None>
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
LD                       : Results for LD coefficients:
                         : -----------------------
                         : Variable:  Coefficient:
                         : -----------------------
                         :     mass:       +0.004
                         :     tau1:       +0.069
                         :     tau2:       +4.141
                         :     tau3:       -3.335
                         :     tau4:       -7.404
                         : (offset):       -0.209
                         : -----------------------
                         : Elapsed time for training with 450000 events: 0.243 sec         
LD                       : [dataset] : Evaluation of LD on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.0925 sec       
                         : <CreateMVAPdfs> Separation from histogram (PDF): 0.485 (0.000)
                         : Dataset[dataset] : Evaluation of LD on training sample
                         : Creating xml weight file: dataset/weights/TMVAClassification_LD.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_LD.class.C
Factory                  : Training finished
                         : 
Factory                  : Train method: FDA_GA for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ FDA_GA ] :
                         : 
                         : --- Short description:
                         : 
                         : The function discriminant analysis (FDA) is a classifier suitable 
                         : to solve linear or simple nonlinear discrimination problems.
                         : 
                         : The user provides the desired function with adjustable parameters
                         : via the configuration option string, and FDA fits the parameters to
                         : it, requiring the signal (background) function value to be as close
                         : as possible to 1 (0). Its advantage over the more involved and
                         : automatic nonlinear discriminators is the simplicity and transparency 
                         : of the discrimination expression. A shortcoming is that FDA will
                         : underperform for involved problems with complicated, phase space
                         : dependent nonlinear correlations.
                         : 
                         : Please consult the Users Guide for the format of the formula string
                         : and the allowed parameter ranges:
                         : http://tmva.sourceforge.net/docu/TMVAUsersGuide.pdf
                         : 
                         : --- Performance optimisation:
                         : 
                         : The FDA performance depends on the complexity and fidelity of the
                         : user-defined discriminator function. As a general rule, it should
                         : be able to reproduce the discrimination power of any linear
                         : discriminant analysis. To reach into the nonlinear domain, it is
                         : useful to inspect the correlation profiles of the input variables,
                         : and add quadratic and higher polynomial terms between variables as
                         : necessary. Comparison with more involved nonlinear classifiers can
                         : be used as a guide.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : Depending on the function used, the choice of "FitMethod" is
                         : crucial for getting valuable solutions with FDA. As a guideline it
                         : is recommended to start with "FitMethod=MINUIT". When more complex
                         : functions are used where MINUIT does not converge to reasonable
                         : results, the user should switch to non-gradient FitMethods such
                         : as GeneticAlgorithm (GA) or Monte Carlo (MC). It might prove to be
                         : useful to combine GA (or MC) with MINUIT by setting the option
                         : "Converger=MINUIT". GA (MC) will then set the starting parameters
                         : for MINUIT such that the basic quality of GA (MC) of finding global
                         : minima is combined with the efficacy of MINUIT of finding local
                         : minima.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
FitterBase               : <GeneticFitter> Optimisation, please be patient ... (inaccurate progress timing for GA)
                         : Elapsed time: 487 sec                            
FDA_GA                   : Results for parameter fit using "GA" fitter:
                         : -----------------------
                         : Parameter:  Fit result:
                         : -----------------------
                         :    Par(0):    0.226929
                         :    Par(1):           0
                         :    Par(2):     2.50819
                         :    Par(3):     4.77447
                         :    Par(4):    -9.39752
                         : -----------------------
                         : Discriminator expression: "(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3"
                         : Value of estimator at minimum: 0.368397
                         : Elapsed time for training with 450000 events: 501 sec         
FDA_GA                   : [dataset] : Evaluation of FDA_GA on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.0971 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_FDA_GA.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_FDA_GA.class.C
Factory                  : Training finished
                         : 
Factory                  : Train method: MLPBNN for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ MLPBNN ] :
                         : 
                         : --- Short description:
                         : 
                         : The MLP artificial neural network (ANN) is a traditional feed-
                         : forward multilayer perceptron implementation. The MLP has a user-
                         : defined hidden layer architecture, while the number of input (output)
                         : nodes is determined by the input variables (output classes, i.e., 
                         : signal and one background). 
                         : 
                         : --- Performance optimisation:
                         : 
                         : Neural networks are stable and performing for a large variety of 
                         : linear and non-linear classification problems. However, in contrast
                         : to (e.g.) boosted decision trees, the user is advised to reduce the 
                         : number of input variables that have only little discrimination power. 
                         : 
                         : In the tests we have carried out so far, the MLP and ROOT networks
                         : (TMlpANN, interfaced via TMVA) performed equally well, with however
                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural 
                         : net (CFMlpANN) exhibited worse classification performance in these
                         : tests, which is partly due to the slow convergence of its training
                         : (at least 10k training cycles are required to achieve approximately
                         : competitive results).
                         : 
                         : Overtraining: only the TMlpANN performs an explicit separation of the
                         : full training sample into independent training and validation samples.
                         : We have found that in most high-energy physics applications the 
                         : available degrees of freedom (training events) are sufficient to 
                         : constrain the weights of the relatively simple architectures required
                         : to achieve good performance. Hence no overtraining should occur, and 
                         : the use of validation samples would only reduce the available training
                         : information. However, if the performance on the training sample is 
                         : found to be significantly better than the one found with the inde-
                         : pendent test sample, caution is needed. The results for these samples 
                         : are printed to standard output at the end of each training job.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : The hidden layer architecture for all ANNs is defined by the option
                         : "HiddenLayers=N+1,N,...", where here the first hidden layer has N+1
                         : neurons and the second N neurons (and so on), and where N is the number  
                         : of input variables. Excessive numbers of hidden layers should be avoided,
                         : in favour of more neurons in the first hidden layer.
                         : 
                         : The number of cycles should be above 500. As said, if the number of
                         : adjustable weights is small compared to the training sample size,
                         : using a large number of training samples should not lead to overtraining.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:   -0.73532    0.12899   [    -1.0000     1.0000 ]
                         :     tau1:   -0.50290    0.29329   [    -1.0000     1.0000 ]
                         :     tau2:   -0.62354    0.21478   [    -1.0000     1.0000 ]
                         :     tau3:   -0.61587    0.20225   [    -1.0000     1.0000 ]
                         :     tau4:   -0.62966    0.18565   [    -1.0000     1.0000 ]
                         : -----------------------------------------------------------
                         : Training Network
                         : 
                         : Finalizing handling of Regulator terms, trainE=0.74392 testE=0.750425 0.7439/0.7504/59]   
                         : Done with handling of Regulator terms
                         : Elapsed time for training with 450000 events: 374 sec         
MLPBNN                   : [dataset] : Evaluation of MLPBNN on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.498 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_MLPBNN.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_MLPBNN.class.C
                         : Write special histos to file: TMVA.root:/dataset/Method_MLP/MLPBNN
Factory                  : Training finished
                         : 
Factory                  : Train method: DNN_CPU for Classification
                         : 
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:   -0.73532    0.12899   [    -1.0000     1.0000 ]
                         :     tau1:   -0.50290    0.29329   [    -1.0000     1.0000 ]
                         :     tau2:   -0.62354    0.21478   [    -1.0000     1.0000 ]
                         :     tau3:   -0.61587    0.20225   [    -1.0000     1.0000 ]
                         :     tau4:   -0.62966    0.18565   [    -1.0000     1.0000 ]
                         : -----------------------------------------------------------
                         : Start of deep neural network training on CPU using MT,  nthreads = 1
                         : 
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:   -0.73532    0.12899   [    -1.0000     1.0000 ]
                         :     tau1:   -0.50290    0.29329   [    -1.0000     1.0000 ]
                         :     tau2:   -0.62354    0.21478   [    -1.0000     1.0000 ]
                         :     tau3:   -0.61587    0.20225   [    -1.0000     1.0000 ]
                         :     tau4:   -0.62966    0.18565   [    -1.0000     1.0000 ]
                         : -----------------------------------------------------------
                         : *****   Deep Learning Network *****
DEEP NEURAL NETWORK:   Depth = 4  Input = ( 1, 1, 5 )  Batch size = 100  Loss function = C
	Layer 0	 DENSE Layer: 	 ( Input =     5 , Width =   128 ) 	Output = (  1 ,   100 ,   128 ) 	 Activation Function = Tanh
	Layer 1	 DENSE Layer: 	 ( Input =   128 , Width =   128 ) 	Output = (  1 ,   100 ,   128 ) 	 Activation Function = Tanh	 Dropout prob. = 0.5
	Layer 2	 DENSE Layer: 	 ( Input =   128 , Width =   128 ) 	Output = (  1 ,   100 ,   128 ) 	 Activation Function = Tanh	 Dropout prob. = 0.5
	Layer 3	 DENSE Layer: 	 ( Input =   128 , Width =     1 ) 	Output = (  1 ,   100 ,     1 ) 	 Activation Function = Identity	 Dropout prob. = 0.5
                         : Using 360000 events for training and 90000 for testing
                         : Compute initial loss  on the validation data 
                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.01 regularization 0 minimum error = 0.684255
                         : --------------------------------------------------------------
                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps
                         : --------------------------------------------------------------
                         :    Start epoch iteration ...
                         :          1 Minimum Test error found - save the configuration 
                         :          1 |     0.422658    0.372642      26.166     2.10898     14964.4           0
                         :          2 Minimum Test error found - save the configuration 
                         :          2 |     0.408894    0.367348     26.2674     2.12011     14908.5           0
                         :          3 |     0.407353    0.378165     25.9832     2.10209     15074.7           1
                         :          4 |     0.406173    0.372879     25.6804     2.07545       15251           2
                         :          5 |     0.404737    0.374692     25.6111     2.02383     15262.5           3
                         :          6 |     0.406635    0.381539     25.5883     2.05033     15294.4           4
                         :          7 |     0.405224    0.380637     25.4715      2.0381     15362.7           5
                         :          8 Minimum Test error found - save the configuration 
                         :          8 |     0.406448    0.365827     25.4119     2.04117     15403.9           0
                         :          9 |     0.403386    0.378297     25.3845     2.03345     15416.9           1
                         :         10 |      0.40532    0.369255     25.2837      2.0299     15481.3           2
                         :         11 |     0.404531    0.368583     25.2613     2.02514     15493.1           3
                         :         12 Minimum Test error found - save the configuration 
                         :         12 |     0.403375    0.364709     25.1941     2.00766     15526.3           0
                         :         13 Minimum Test error found - save the configuration 
                         :         13 |     0.406501    0.363521     25.1643     2.00973     15547.7           0
                         :         14 |     0.405049    0.370931     24.9703      2.0098     15679.1           1
                         :         15 |     0.403366    0.365967     25.0386     2.00458       15629           2
                         :         16 |     0.402593    0.380927     24.9656     1.99499     15672.2           3
                         :         17 |     0.402567    0.366626     25.0491     2.00531     15622.4           4
                         :         18 |     0.401879    0.374337     24.9977     1.95125     15620.7           5
                         :         19 |     0.403479    0.379222     24.9195      1.9941     15703.1           6
                         :         20 |     0.403098    0.377232     25.0156     1.93757     15599.3           7
                         :         21 |     0.403446    0.375745     24.8229     1.99228     15768.3           8
                         :         22 |     0.403451    0.379339     24.7819     1.93409     15756.5           9
                         :         23 |        0.403    0.378087     24.9469     1.99304     15683.6          10
                         :         24 |     0.402292    0.378372     24.9964           2     15654.6          11
                         :         25 |     0.402488    0.367234      24.985     1.98935     15655.1          12
                         :         26 |     0.401504    0.377008     24.9843     1.98301     15651.3          13
                         :         27 |     0.403761    0.364911     24.9087      1.9873     15705.9          14
                         :         28 |     0.401489    0.375815     24.8854     1.97919     15716.3          15
                         :         29 |     0.403955    0.386621     24.8637     1.93056     15697.8          16
                         :         30 |     0.400975    0.366976     24.6074     1.98711     15914.9          17
                         :         31 |     0.402073    0.373575     24.8886     1.95103     15694.8          18
                         :         32 |     0.402636    0.372008     24.9978     1.96699     15631.3          19
                         :         33 |     0.402408    0.379117      24.986     1.96335     15636.8          20
                         :         34 |     0.404523    0.371207     24.9553     1.98493     15672.4          21
                         : 
                         : Elapsed time for training with 450000 events: 858 sec         
                         : Evaluate deep neural network on CPU using batches with size = 100
                         : 
DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 9.8 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_DNN_CPU.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_DNN_CPU.class.C
Factory                  : Training finished
                         : 
Factory                  : Train method: BDT for Classification
                         : 
BDT                      : #events: (reweighted) sig: 225000 bkg: 225000
                         : #events: (unweighted) sig: 225000 bkg: 225000
                         : Training 850 Decision Trees ... patience please
                         : Elapsed time for training with 450000 events: 180 sec         
BDT                      : [dataset] : Evaluation of BDT on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 16.1 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_BDT.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_BDT.class.C
                         : TMVA.root:/dataset/Method_BDT/BDT
Factory                  : Training finished
                         : 
Factory                  : Train method: RuleFit for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ RuleFit ] :
                         : 
                         : --- Short description:
                         : 
                         : This method uses a collection of so called rules to create a
                         : discriminating scoring function. Each rule consists of a series
                         : of cuts in parameter space. The ensemble of rules are created
                         : from a forest of decision trees, trained using the training data.
                         : Each node (apart from the root) corresponds to one rule.
                         : The scoring function is then obtained by linearly combining
                         : the rules. A fitting procedure is applied to find the optimum
                         : set of coefficients. The goal is to find a model with few rules
                         : but with a strong discriminating power.
                         : 
                         : --- Performance optimisation:
                         : 
                         : There are two important considerations to make when optimising:
                         : 
                         :   1. Topology of the decision tree forest
                         :   2. Fitting of the coefficients
                         : 
                         : The maximum complexity of the rules is defined by the size of
                         : the trees. Large trees will yield many complex rules and capture
                         : higher order correlations. On the other hand, small trees will
                         : lead to a smaller ensemble with simple rules, only capable of
                         : modeling simple structures.
                         : Several parameters exists for controlling the complexity of the
                         : rule ensemble.
                         : 
                         : The fitting procedure searches for a minimum using a gradient
                         : directed path. Apart from step size and number of steps, the
                         : evolution of the path is defined by a cut-off parameter, tau.
                         : This parameter is unknown and depends on the training data.
                         : A large value will tend to give large weights to a few rules.
                         : Similarly, a small value will lead to a large set of rules
                         : with similar weights.
                         : 
                         : A final point is the model used; rules and/or linear terms.
                         : For a given training sample, the result may improve by adding
                         : linear terms. If best performance is obtained using only linear
                         : terms, it is very likely that the Fisher discriminant would be
                         : a better choice. Ideally the fitting procedure should be able to
                         : make this choice by giving appropriate weights for either terms.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : I.  TUNING OF RULE ENSEMBLE:
                         : 
                         :    ForestType  : Recommended is to use the default "AdaBoost".
                         :    nTrees      : More trees leads to more rules but also slow
                         :                  performance. With too few trees the risk is
                         :                  that the rule ensemble becomes too simple.
                         :    fEventsMin  
                         :    fEventsMax  : With a lower min, more large trees will be generated
                         :                  leading to more complex rules.
                         :                  With a higher max, more small trees will be
                         :                  generated leading to more simple rules.
                         :                  By changing this range, the average complexity
                         :                  of the rule ensemble can be controlled.
                         :    RuleMinDist : By increasing the minimum distance between
                         :                  rules, fewer and more diverse rules will remain.
                         :                  Initially it is a good idea to keep this small
                         :                  or zero and let the fitting do the selection of
                         :                  rules. In order to reduce the ensemble size,
                         :                  the value can then be increased.
                         : 
                         : II. TUNING OF THE FITTING:
                         : 
                         :    GDPathEveFrac : fraction of events in path evaluation
                         :                  Increasing this fraction will improve the path
                         :                  finding. However, a too high value will give few
                         :                  unique events available for error estimation.
                         :                  It is recommended to use the default = 0.5.
                         :    GDTau         : cutoff parameter tau
                         :                  By default this value is set to -1.0.
                         :                  This means that the cut off parameter is
                         :                  automatically estimated. In most cases
                         :                  this should be fine. However, you may want
                         :                  to fix this value if you already know it
                         :                  and want to reduce on training time.
                         :    GDTauPrec     : precision of estimated tau
                         :                  Increase this precision to find a more
                         :                  optimum cut-off parameter.
                         :    GDNStep       : number of steps in path search
                         :                  If the number of steps is too small, then
                         :                  the program will give a warning message.
                         : 
                         : III. WARNING MESSAGES
                         : 
                         : Risk(i+1)>=Risk(i) in path
                         : Chaotic behaviour of risk evolution.
                         :                  The error rate was still decreasing at the end
                         :                  By construction the Risk should always decrease.
                         :                  However, if the training sample is too small or
                         :                  the model is overtrained, such warnings can
                         :                  occur.
                         :                  The warnings can safely be ignored if only a
                         :                  few (<3) occur. If more warnings are generated,
                         :                  the fitting fails.
                         :                  A remedy may be to increase the value
                         :                  GDValidEveFrac to 1.0 (or a larger value).
                         :                  In addition, if GDPathEveFrac is too high
                         :                  the same warnings may occur since the events
                         :                  used for error estimation are also used for
                         :                  path estimation.
                         :                  Another possibility is to modify the model - 
                         :                  See above on tuning the rule ensemble.
                         : 
                         : The error rate was still decreasing at the end of the path
                         :                  Too few steps in path! Increase GDNSteps.
                         : 
                         : Reached minimum early in the search
                         :                  Minimum was found early in the fitting. This
                         :                  may indicate that the used step size GDStep.
                         :                  was too large. Reduce it and rerun.
                         :                  If the results still are not OK, modify the
                         :                  model either by modifying the rule ensemble
                         :                  or add/remove linear terms
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
RuleFit                  : -------------------RULE ENSEMBLE SUMMARY------------------------
                         : Tree training method               : AdaBoost
                         : Number of events per tree          : 450000
                         : Number of trees                    : 20
                         : Number of generated rules          : 220
                         : Idem, after cleanup                : 94
                         : Average number of cuts per rule    :     2.82
                         : Spread in number of cuts per rules :     1.12
                         : ----------------------------------------------------------------
                         : 
                         : GD path scan - the scan stops when the max num. of steps is reached or a min is found
                         : Estimating the cutoff parameter tau. The estimated time is a pessimistic maximum.
                         : Best path found with tau = 0.9400 after 142 sec      
                         : Fitting model...
<WARNING>                : [>>>>>>>>>>>>>>>] (100%, time left: 0 sec)  
                         : Minimisation elapsed time : 512 sec                      
                         : ----------------------------------------------------------------
                         : Found minimum at step 10000 with error = 0.507189
                         : Reason for ending loop: end of loop reached
                         : ----------------------------------------------------------------
                         : The error rate was still decreasing at the end of the path
                         : Increase number of steps (GDNSteps).
                         : Removed 71 out of a total of 94 rules with importance < 0.001
                         : 
                         : ================================================================
                         :                           M o d e l                             
                         : ================================================================
RuleFit                  : Offset (a0) = -0.260196
                         : ------------------------------------
                         : Linear model (weights unnormalised)
                         : ------------------------------------
                         : Variable :     Weights : Importance
                         : ------------------------------------
                         :     mass :   2.290e-03 :  0.392
                         :     tau1-> importance below threshold =  0.000
                         :     tau2 :   1.341e-01 :  0.017
                         :     tau3-> importance below threshold =  0.000
                         :     tau4 :  -7.334e+00 :  0.426
                         : ------------------------------------
                         : Number of rules = 23
                         : Printing the first 10 rules, ordered in importance.
                         : Rule    1 : Importance  = 1.0000
                         :             Cut  1 :        142 < mass             
                         : Rule    2 : Importance  = 0.6404
                         :             Cut  1 :              mass <       94.7
                         : Rule    3 : Importance  = 0.2623
                         :             Cut  1 :     0.0847 < tau1             
                         :             Cut  2 :              tau3 <     0.0531
                         : Rule    4 : Importance  = 0.2231
                         :             Cut  1 :        142 < mass             
                         :             Cut  2 :              tau2 <     0.0887
                         : Rule    5 : Importance  = 0.1479
                         :             Cut  1 :        145 < mass             
                         :             Cut  2 :              tau1 <       0.25
                         : Rule    6 : Importance  = 0.1409
                         :             Cut  1 :              mass <        142
                         :             Cut  2 :     0.0827 < tau1             
                         :             Cut  3 :              tau2 <     0.0698
                         : Rule    7 : Importance  = 0.1299
                         :             Cut  1 :       0.08 < tau2             
                         :             Cut  2 :     0.0439 < tau4 <     0.0648
                         : Rule    8 : Importance  = 0.1288
                         :             Cut  1 :              tau2 <      0.152
                         :             Cut  2 :     0.0588 < tau4             
                         : Rule    9 : Importance  = 0.0733
                         :             Cut  1 :              tau1 <     0.0931
                         :             Cut  2 :              tau4 <      0.044
                         : Rule   10 : Importance  = 0.0694
                         :             Cut  1 :       94.7 < mass             
                         :             Cut  2 :     0.0723 < tau1             
                         :             Cut  3 :              tau4 <     0.0387
                         : Skipping the next 13 rules
                         : ================================================================
                         : 
<WARNING>                : No input variable directory found - BUG?
                         : Elapsed time for training with 450000 events: 668 sec         
RuleFit                  : [dataset] : Evaluation of RuleFit on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.18 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_RuleFit.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_RuleFit.class.C
                         : TMVA.root:/dataset/Method_RuleFit/RuleFit
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
Likelihood               : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable  : Delta Separation
                         : -----------------------------------
                         :    1 : mass      : 6.068e-02
                         :    2 : tau4      : 4.634e-03
                         :    3 : tau2      : -3.603e-03
                         :    4 : tau3      : -5.241e-03
                         :    5 : tau1      : -2.674e-02
                         : -----------------------------------
LikelihoodPCA            : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable  : Delta Separation
                         : -----------------------------------
                         :    1 : mass      : 1.124e-01
                         :    2 : tau2      : 3.317e-02
                         :    3 : tau3      : 2.259e-02
                         :    4 : tau1      : 1.503e-03
                         :    5 : tau4      : -9.329e-03
                         : -----------------------------------
                         : No variable ranking supplied by classifier: KNN
LD                       : Ranking result (top variable is best ranked)
                         : -------------------------------
                         : Rank : Variable  : Discr. power
                         : -------------------------------
                         :    1 : tau4      : 7.404e+00
                         :    2 : tau2      : 4.141e+00
                         :    3 : tau3      : 3.335e+00
                         :    4 : tau1      : 6.889e-02
                         :    5 : mass      : 4.262e-03
                         : -------------------------------
                         : No variable ranking supplied by classifier: FDA_GA
MLPBNN                   : Ranking result (top variable is best ranked)
                         : -----------------------------
                         : Rank : Variable  : Importance
                         : -----------------------------
                         :    1 : mass      : 3.756e+01
                         :    2 : tau4      : 2.524e+01
                         :    3 : tau2      : 1.104e+01
                         :    4 : tau3      : 1.073e+01
                         :    5 : tau1      : 9.984e+00
                         : -----------------------------
                         : No variable ranking supplied by classifier: DNN_CPU
BDT                      : Ranking result (top variable is best ranked)
                         : --------------------------------------
                         : Rank : Variable  : Variable Importance
                         : --------------------------------------
                         :    1 : mass      : 2.869e-01
                         :    2 : tau1      : 1.989e-01
                         :    3 : tau2      : 1.932e-01
                         :    4 : tau4      : 1.798e-01
                         :    5 : tau3      : 1.413e-01
                         : --------------------------------------
RuleFit                  : Ranking result (top variable is best ranked)
                         : -----------------------------
                         : Rank : Variable  : Importance
                         : -----------------------------
                         :    1 : mass      : 1.000e+00
                         :    2 : tau4      : 3.056e-01
                         :    3 : tau1      : 1.995e-01
                         :    4 : tau2      : 1.727e-01
                         :    5 : tau3      : 8.136e-02
                         : -----------------------------
TH1.Print Name  = TrainingHistory_DNN_CPU_trainingError, Entries= 0, Total sum= 13.7513
TH1.Print Name  = TrainingHistory_DNN_CPU_valError, Entries= 0, Total sum= 12.6993
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
                         : Reading weight file: dataset/weights/TMVAClassification_Likelihood.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_LikelihoodPCA.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_KNN.weights.xml
                         : Creating kd-tree with 450000 events
                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)
ModulekNN                : Optimizing tree for 5 variables with 450000 values
                         : <Fill> Class 1 has   225000 events
                         : <Fill> Class 2 has   225000 events
                         : Reading weight file: dataset/weights/TMVAClassification_LD.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_FDA_GA.weights.xml
                         : User-defined formula string       : "(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3"
                         : TFormula-compatible formula string: "[0]+[1]*[5]+[2]*[6]+[3]*[7]+[4]*[8]"
                         : Reading weight file: dataset/weights/TMVAClassification_MLPBNN.weights.xml
MLPBNN                   : Building Network. 
                         : Initializing weights
                         : Reading weight file: dataset/weights/TMVAClassification_DNN_CPU.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_BDT.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_RuleFit.weights.xml
Factory                  : Test all methods
Factory                  : Test method: Likelihood for Classification performance
                         : 
Likelihood               : [dataset] : Evaluation of Likelihood on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.292 sec       
Factory                  : Test method: LikelihoodPCA for Classification performance
                         : 
LikelihoodPCA            : [dataset] : Evaluation of LikelihoodPCA on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.627 sec       
Factory                  : Test method: KNN for Classification performance
                         : 
KNN                      : [dataset] : Evaluation of KNN on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 123 sec       
Factory                  : Test method: LD for Classification performance
                         : 
LD                       : [dataset] : Evaluation of LD on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.089 sec       
                         : Dataset[dataset] : Evaluation of LD on testing sample
Factory                  : Test method: FDA_GA for Classification performance
                         : 
FDA_GA                   : [dataset] : Evaluation of FDA_GA on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.0883 sec       
Factory                  : Test method: MLPBNN for Classification performance
                         : 
MLPBNN                   : [dataset] : Evaluation of MLPBNN on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.523 sec       
Factory                  : Test method: DNN_CPU for Classification performance
                         : 
                         : Evaluate deep neural network on CPU using batches with size = 1000
                         : 
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:   -0.80841    0.10510   [    -1.0000     1.9228 ]
                         :     tau1:   -0.62809    0.28230   [    -1.0000    0.94081 ]
                         :     tau2:   -0.70052    0.18937   [    -1.0000    0.89274 ]
                         :     tau3:   -0.64829    0.20495   [    -1.0000    0.99428 ]
                         :     tau4:   -0.64755    0.20183   [    -1.0000     1.0948 ]
                         : -----------------------------------------------------------
DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 9.97 sec       
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [dataset] : Evaluation of BDT on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 15.1 sec       
Factory                  : Test method: RuleFit for Classification performance
                         : 
RuleFit                  : [dataset] : Evaluation of RuleFit on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.201 sec       
Factory                  : Evaluate all methods
Factory                  : Evaluate classifier: Likelihood
                         : 
Likelihood               : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_Likelihood     : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:     95.204     52.228   [-7.6294e-06     1452.4 ]
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: LikelihoodPCA
                         : 
TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:    0.19541     52.228   [    -95.008     1357.4 ]
                         :     tau1:-0.00044564   0.060604   [    -1.8293    0.47179 ]
                         :     tau2:-2.1319e-05   0.027317   [   -0.19836    0.23753 ]
                         :     tau3: 1.5368e-05  0.0089130   [   -0.15622   0.054220 ]
                         :     tau4: 1.6313e-06  0.0030423   [  -0.025653   0.056104 ]
                         : -----------------------------------------------------------
LikelihoodPCA            : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:    0.19541     52.228   [    -95.008     1357.4 ]
                         :     tau1:-0.00044564   0.060604   [    -1.8293    0.47179 ]
                         :     tau2:-2.1319e-05   0.027317   [   -0.19836    0.23753 ]
                         :     tau3: 1.5368e-05  0.0089130   [   -0.15622   0.054220 ]
                         :     tau4: 1.6313e-06  0.0030423   [  -0.025653   0.056104 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: KNN
                         : 
KNN                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_KNN            : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:     95.204     52.228   [-7.6294e-06     1452.4 ]
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: LD
                         : 
LD                       : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
                         : Also filling probability and rarity histograms (on request)...
TFHandler_LD             : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:     95.204     52.228   [-7.6294e-06     1452.4 ]
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: FDA_GA
                         : 
FDA_GA                   : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_FDA_GA         : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:     95.204     52.228   [-7.6294e-06     1452.4 ]
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: MLPBNN
                         : 
TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:   -0.80841    0.10510   [    -1.0000     1.9228 ]
                         :     tau1:   -0.62809    0.28230   [    -1.0000    0.94081 ]
                         :     tau2:   -0.70052    0.18937   [    -1.0000    0.89274 ]
                         :     tau3:   -0.64829    0.20495   [    -1.0000    0.99428 ]
                         :     tau4:   -0.64755    0.20183   [    -1.0000     1.0948 ]
                         : -----------------------------------------------------------
MLPBNN                   : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:   -0.80841    0.10510   [    -1.0000     1.9228 ]
                         :     tau1:   -0.62809    0.28230   [    -1.0000    0.94081 ]
                         :     tau2:   -0.70052    0.18937   [    -1.0000    0.89274 ]
                         :     tau3:   -0.64829    0.20495   [    -1.0000    0.99428 ]
                         :     tau4:   -0.64755    0.20183   [    -1.0000     1.0948 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: DNN_CPU
                         : 
DNN_CPU                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
                         : Evaluate deep neural network on CPU using batches with size = 1000
                         : 
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:   -0.73532    0.12899   [    -1.0000     1.0000 ]
                         :     tau1:   -0.50290    0.29329   [    -1.0000     1.0000 ]
                         :     tau2:   -0.62354    0.21478   [    -1.0000     1.0000 ]
                         :     tau3:   -0.61587    0.20225   [    -1.0000     1.0000 ]
                         :     tau4:   -0.62966    0.18565   [    -1.0000     1.0000 ]
                         : -----------------------------------------------------------
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:   -0.80841    0.10510   [    -1.0000     1.9228 ]
                         :     tau1:   -0.62809    0.28230   [    -1.0000    0.94081 ]
                         :     tau2:   -0.70052    0.18937   [    -1.0000    0.89274 ]
                         :     tau3:   -0.64829    0.20495   [    -1.0000    0.99428 ]
                         :     tau4:   -0.64755    0.20183   [    -1.0000     1.0948 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:     95.204     52.228   [-7.6294e-06     1452.4 ]
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: RuleFit
                         : 
RuleFit                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_RuleFit        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     mass:     95.204     52.228   [-7.6294e-06     1452.4 ]
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       BDT            : 0.925
                         : dataset       KNN            : 0.920
                         : dataset       DNN_CPU        : 0.917
                         : dataset       MLPBNN         : 0.915
                         : dataset       RuleFit        : 0.899
                         : dataset       LD             : 0.892
                         : dataset       LikelihoodPCA  : 0.887
                         : dataset       FDA_GA         : 0.840
                         : dataset       Likelihood     : 0.820
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              BDT            : 0.401 (0.401)       0.773 (0.776)      0.939 (0.941)
                         : dataset              KNN            : 0.331 (0.460)       0.767 (0.793)      0.936 (0.941)
                         : dataset              DNN_CPU        : 0.292 (0.295)       0.745 (0.748)      0.935 (0.936)
                         : dataset              MLPBNN         : 0.305 (0.301)       0.738 (0.742)      0.931 (0.932)
                         : dataset              RuleFit        : 0.230 (0.228)       0.697 (0.698)      0.913 (0.915)
                         : dataset              LD             : 0.058 (0.057)       0.691 (0.694)      0.915 (0.917)
                         : dataset              LikelihoodPCA  : 0.198 (0.213)       0.673 (0.675)      0.883 (0.886)
                         : dataset              FDA_GA         : 0.047 (0.047)       0.454 (0.456)      0.857 (0.857)
                         : dataset              Likelihood     : 0.038 (0.039)       0.471 (0.472)      0.798 (0.799)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 497441 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 450000 events
                         : 
Factory                  : Thank you for using TMVA!
                         : For citation information, please visit: http://tmva.sf.net/citeTMVA.html
==> Wrote root file: TMVA.root
==> TMVAClassification is done!
--- Launch TMVA GUI to view input file: TMVA.root
=== Note: inactive buttons indicate classifiers that were not trained, ===
===       or functionalities that were not invoked during the training ===

