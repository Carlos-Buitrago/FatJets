--- TMVAClassification       : Using input files: ./pp_tt_hadronic_14TeV500kEvtsGenCutT350_CutQCD350_InclusiveCut350_delphes_events.root and ./pp_QCD_14TeV500kEvtsGenCutQCD350_InclusiveCut350_delphes_events.root
DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree Delphes of type Signal with 500000 events
DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree Delphes of type Background with 447443 events
Factory                  : Booking method: Likelihood
                         : 
Factory                  : Booking method: LikelihoodPCA
                         : 
LikelihoodPCA            : [dataset] : Create Transformation "PCA" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : Booking method: KNN
                         : 
Factory                  : Booking method: LD
                         : 
                         : Rebuilding Dataset dataset
                         : Building event vectors for type 2 Signal
                         : Dataset[dataset] :  create input formulas for tree Delphes
                         : Building event vectors for type 2 Background
                         : Dataset[dataset] :  create input formulas for tree Delphes
DataSetFactory           : [dataset] : Number of events in input trees
                         : 
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 225000
                         : Signal     -- testing events             : 275000
                         : Signal     -- training and testing events: 500000
                         : Background -- training events            : 225000
                         : Background -- testing events             : 222441
                         : Background -- training and testing events: 447441
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : ----------------------------------------
                         :             tau1    tau2    tau3    tau4
                         :    tau1:  +1.000  +0.799  +0.643  +0.614
                         :    tau2:  +0.799  +1.000  +0.828  +0.766
                         :    tau3:  +0.643  +0.828  +1.000  +0.939
                         :    tau4:  +0.614  +0.766  +0.939  +1.000
                         : ----------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : ----------------------------------------
                         :             tau1    tau2    tau3    tau4
                         :    tau1:  +1.000  +0.823  +0.778  +0.767
                         :    tau2:  +0.823  +1.000  +0.951  +0.928
                         :    tau3:  +0.778  +0.951  +1.000  +0.984
                         :    tau4:  +0.767  +0.928  +0.984  +1.000
                         : ----------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : Booking method: FDA_GA
                         : 
                         : Create parameter interval for parameter 0 : [-1,1]
                         : Create parameter interval for parameter 1 : [-10,10]
                         : Create parameter interval for parameter 2 : [-10,10]
                         : Create parameter interval for parameter 3 : [-10,10]
                         : Create parameter interval for parameter 4 : [-10,10]
                         : User-defined formula string       : "(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3"
                         : TFormula-compatible formula string: "[0]+[1]*[5]+[2]*[6]+[3]*[7]+[4]*[8]"
Factory                  : Booking method: MLPBNN
                         : 
MLPBNN                   : [dataset] : Create Transformation "N" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
MLPBNN                   : Building Network. 
                         : Initializing weights
Factory                  : Booking method: DNN_CPU
                         : 
                         : Parsing option string: 
                         : ... "!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:WeightInitialization=XAVIERUNIFORM:Layout=TANH|128,TANH|128,TANH|128,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5:Architecture=CPU"
                         : The following options are set:
                         : - By User:
                         :     <none>
                         : - Default:
                         :     Boost_num: "0" [Number of times the classifier will be boosted]
                         : Parsing option string: 
                         : ... "!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=N:WeightInitialization=XAVIERUNIFORM:Layout=TANH|128,TANH|128,TANH|128,LINEAR:TrainingStrategy=LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5:Architecture=CPU"
                         : The following options are set:
                         : - By User:
                         :     V: "True" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
                         :     VarTransform: "N" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
                         :     H: "False" [Print method-specific help message]
                         :     Layout: "TANH|128,TANH|128,TANH|128,LINEAR" [Layout of the network.]
                         :     ErrorStrategy: "CROSSENTROPY" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]
                         :     WeightInitialization: "XAVIERUNIFORM" [Weight initialization strategy]
                         :     Architecture: "CPU" [Which architecture to perform the training on.]
                         :     TrainingStrategy: "LearningRate=1e-2,Momentum=0.9,ConvergenceSteps=20,BatchSize=100,TestRepetitions=1,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5" [Defines the training strategies.]
                         : - Default:
                         :     VerbosityLevel: "Default" [Verbosity level]
                         :     CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
                         :     IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
                         :     InputLayout: "0|0|0" [The Layout of the input]
                         :     BatchLayout: "0|0|0" [The Layout of the batch]
                         :     RandomSeed: "0" [Random seed used for weight initialization and batch shuffling]
                         :     ValidationSize: "20%" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]
DNN_CPU                  : [dataset] : Create Transformation "N" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
                         : Will now use the CPU architecture with BLAS and IMT support !
Factory                  : Booking method: BDT
                         : 
Factory                  : Booking method: RuleFit
                         : 
Factory                  : Train all methods
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : [dataset] : Create Transformation "D" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : [dataset] : Create Transformation "P" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : [dataset] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
Factory                  : [dataset] : Create Transformation "D" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'tau1' <---> Output : variable 'tau1'
                         : Input : variable 'tau2' <---> Output : variable 'tau2'
                         : Input : variable 'tau3' <---> Output : variable 'tau3'
                         : Input : variable 'tau4' <---> Output : variable 'tau4'
TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:    0.16202   0.095592   [     0.0000    0.65185 ]
                         :     tau2:   0.082311   0.046960   [     0.0000    0.43728 ]
                         :     tau3:   0.053519   0.028178   [     0.0000    0.27865 ]
                         :     tau4:   0.042640   0.021375   [     0.0000    0.23027 ]
                         : -----------------------------------------------------------
                         : Preparing the Decorrelation transformation...
TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:     1.3406     1.0000   [     0.0000     6.9130 ]
                         :     tau2:    0.72365     1.0000   [    -4.6062     8.4406 ]
                         :     tau3:    0.75053     1.0000   [    -5.1687     12.492 ]
                         :     tau4:     1.1691     1.0000   [    -8.8657     9.9892 ]
                         : -----------------------------------------------------------
                         : Preparing the Principle Component (PCA) transformation...
TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1: 2.1062e-12    0.10720   [   -0.19296    0.60779 ]
                         :     tau2: 3.6234e-13   0.029777   [   -0.19769    0.18980 ]
                         :     tau3:-7.6284e-13   0.013970   [  -0.097372   0.076077 ]
                         :     tau4:-3.2902e-13  0.0044548   [  -0.064684   0.026860 ]
                         : -----------------------------------------------------------
                         : Preparing the Gaussian transformation...
                         : Preparing the Decorrelation transformation...
TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:  0.0022409     1.0000   [    -2.2964     7.0765 ]
                         :     tau2:  0.0015080     1.0000   [    -4.4524     8.0625 ]
                         :     tau3:  0.0018940     1.0000   [    -4.4515     14.564 ]
                         :     tau4:  0.0016905     1.0000   [    -8.5823     10.024 ]
                         : -----------------------------------------------------------
                         : Ranking input variables (method unspecific)...
IdTransformation         : Ranking result (top variable is best ranked)
                         : -----------------------------
                         : Rank : Variable  : Separation
                         : -----------------------------
                         :    1 : Tau1      : 2.915e-01
                         :    2 : Tau2      : 1.588e-01
                         :    3 : Tau4      : 6.290e-02
                         :    4 : Tau3      : 6.271e-02
                         : -----------------------------
Factory                  : Train method: Likelihood for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ Likelihood ] :
                         : 
                         : --- Short description:
                         : 
                         : The maximum-likelihood classifier models the data with probability 
                         : density functions (PDF) reproducing the signal and background
                         : distributions of the input variables. Correlations among the 
                         : variables are ignored.
                         : 
                         : --- Performance optimisation:
                         : 
                         : Required for good performance are decorrelated input variables
                         : (PCA transformation via the option "VarTransform=Decorrelate"
                         : may be tried). Irreducible non-linear correlations may be reduced
                         : by precombining strongly correlated input variables, or by simply
                         : removing one of the variables.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : High fidelity PDF estimates are mandatory, i.e., sufficient training 
                         : statistics is required to populate the tails of the distributions
                         : It would be a surprise if the default Spline or KDE kernel parameters
                         : provide a satisfying fit to the data. The user is advised to properly
                         : tune the events per bin and smooth options in the spline cases
                         : individually per variable. If the KDE kernel is used, the adaptive
                         : Gaussian kernel may lead to artefacts, so please always also try
                         : the non-adaptive one.
                         : 
                         : All tuning parameters must be adjusted individually for each input
                         : variable!
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
                         : Filling reference histograms
                         : Building PDF out of reference histograms
                         : Elapsed time for training with 450000 events: 1.8 sec         
Likelihood               : [dataset] : Evaluation of Likelihood on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.255 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_Likelihood.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_Likelihood.class.C
                         : TMVA.root:/dataset/Method_Likelihood/Likelihood
Factory                  : Training finished
                         : 
Factory                  : Train method: LikelihoodPCA for Classification
                         : 
                         : Preparing the Principle Component (PCA) transformation...
TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1: 2.1062e-12    0.10720   [   -0.19296    0.60779 ]
                         :     tau2: 3.6234e-13   0.029777   [   -0.19769    0.18980 ]
                         :     tau3:-7.6284e-13   0.013970   [  -0.097372   0.076077 ]
                         :     tau4:-3.2902e-13  0.0044548   [  -0.064684   0.026860 ]
                         : -----------------------------------------------------------
                         : Filling reference histograms
                         : Building PDF out of reference histograms
                         : Elapsed time for training with 450000 events: 2.16 sec         
LikelihoodPCA            : [dataset] : Evaluation of LikelihoodPCA on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.486 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_LikelihoodPCA.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_LikelihoodPCA.class.C
                         : TMVA.root:/dataset/Method_Likelihood/LikelihoodPCA
Factory                  : Training finished
                         : 
Factory                  : Train method: KNN for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ KNN ] :
                         : 
                         : --- Short description:
                         : 
                         : The k-nearest neighbor (k-NN) algorithm is a multi-dimensional classification
                         : and regression algorithm. Similarly to other TMVA algorithms, k-NN uses a set of
                         : training events for which a classification category/regression target is known. 
                         : The k-NN method compares a test event to all training events using a distance 
                         : function, which is an Euclidean distance in a space defined by the input variables. 
                         : The k-NN method, as implemented in TMVA, uses a kd-tree algorithm to perform a
                         : quick search for the k events with shortest distance to the test event. The method
                         : returns a fraction of signal events among the k neighbors. It is recommended
                         : that a histogram which stores the k-NN decision variable is binned with k+1 bins
                         : between 0 and 1.
                         : 
                         : --- Performance tuning via configuration options: 
                         : 
                         : The k-NN method estimates a density of signal and background events in a 
                         : neighborhood around the test event. The method assumes that the density of the 
                         : signal and background events is uniform and constant within the neighborhood. 
                         : k is an adjustable parameter and it determines an average size of the 
                         : neighborhood. Small k values (less than 10) are sensitive to statistical 
                         : fluctuations and large (greater than 100) values might not sufficiently capture  
                         : local differences between events in the training set. The speed of the k-NN
                         : method also increases with larger values of k. 
                         : 
                         : The k-NN method assigns equal weight to all input variables. Different scales 
                         : among the input variables is compensated using ScaleFrac parameter: the input 
                         : variables are scaled so that the widths for central ScaleFrac*100% events are 
                         : equal among all the input variables.
                         : 
                         : --- Additional configuration options: 
                         : 
                         : The method inclues an option to use a Gaussian kernel to smooth out the k-NN
                         : response. The kernel re-weights events using a distance to the test event.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
KNN                      : <Train> start...
                         : Reading 450000 events
                         : Number of signal events 225000
                         : Number of background events 225000
                         : Creating kd-tree with 450000 events
                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)
ModulekNN                : Optimizing tree for 4 variables with 450000 values
                         : <Fill> Class 1 has   225000 events
                         : <Fill> Class 2 has   225000 events
                         : Elapsed time for training with 450000 events: 0.988 sec         
KNN                      : [dataset] : Evaluation of KNN on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 47.9 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_KNN.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_KNN.class.C
Factory                  : Training finished
                         : 
Factory                  : Train method: LD for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ LD ] :
                         : 
                         : --- Short description:
                         : 
                         : Linear discriminants select events by distinguishing the mean 
                         : values of the signal and background distributions in a trans- 
                         : formed variable space where linear correlations are removed.
                         : The LD implementation here is equivalent to the "Fisher" discriminant
                         : for classification, but also provides linear regression.
                         : 
                         :    (More precisely: the "linear discriminator" determines
                         :     an axis in the (correlated) hyperspace of the input 
                         :     variables such that, when projecting the output classes 
                         :     (signal and background) upon this axis, they are pushed 
                         :     as far as possible away from each other, while events
                         :     of a same class are confined in a close vicinity. The  
                         :     linearity property of this classifier is reflected in the 
                         :     metric with which "far apart" and "close vicinity" are 
                         :     determined: the covariance matrix of the discriminating
                         :     variable space.)
                         : 
                         : --- Performance optimisation:
                         : 
                         : Optimal performance for the linear discriminant is obtained for 
                         : linearly correlated Gaussian-distributed variables. Any deviation
                         : from this ideal reduces the achievable separation power. In 
                         : particular, no discrimination at all is achieved for a variable
                         : that has the same sample mean for signal and background, even if 
                         : the shapes of the distributions are very different. Thus, the linear 
                         : discriminant often benefits from a suitable transformation of the 
                         : input variables. For example, if a variable x in [-1,1] has a 
                         : a parabolic signal distributions, and a uniform background
                         : distributions, their mean value is zero in both cases, leading 
                         : to no separation. The simple transformation x -> |x| renders this 
                         : variable powerful for the use in a linear discriminant.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : <None>
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
LD                       : Results for LD coefficients:
                         : -----------------------
                         : Variable:  Coefficient:
                         : -----------------------
                         :     tau1:       +2.144
                         :     tau2:       +5.260
                         :     tau3:       -0.356
                         :     tau4:      -13.244
                         : (offset):       -0.098
                         : -----------------------
                         : Elapsed time for training with 450000 events: 0.207 sec         
LD                       : [dataset] : Evaluation of LD on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.0878 sec       
                         : <CreateMVAPdfs> Separation from histogram (PDF): 0.387 (0.000)
                         : Dataset[dataset] : Evaluation of LD on training sample
                         : Creating xml weight file: dataset/weights/TMVAClassification_LD.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_LD.class.C
Factory                  : Training finished
                         : 
Factory                  : Train method: FDA_GA for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ FDA_GA ] :
                         : 
                         : --- Short description:
                         : 
                         : The function discriminant analysis (FDA) is a classifier suitable 
                         : to solve linear or simple nonlinear discrimination problems.
                         : 
                         : The user provides the desired function with adjustable parameters
                         : via the configuration option string, and FDA fits the parameters to
                         : it, requiring the signal (background) function value to be as close
                         : as possible to 1 (0). Its advantage over the more involved and
                         : automatic nonlinear discriminators is the simplicity and transparency 
                         : of the discrimination expression. A shortcoming is that FDA will
                         : underperform for involved problems with complicated, phase space
                         : dependent nonlinear correlations.
                         : 
                         : Please consult the Users Guide for the format of the formula string
                         : and the allowed parameter ranges:
                         : http://tmva.sourceforge.net/docu/TMVAUsersGuide.pdf
                         : 
                         : --- Performance optimisation:
                         : 
                         : The FDA performance depends on the complexity and fidelity of the
                         : user-defined discriminator function. As a general rule, it should
                         : be able to reproduce the discrimination power of any linear
                         : discriminant analysis. To reach into the nonlinear domain, it is
                         : useful to inspect the correlation profiles of the input variables,
                         : and add quadratic and higher polynomial terms between variables as
                         : necessary. Comparison with more involved nonlinear classifiers can
                         : be used as a guide.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : Depending on the function used, the choice of "FitMethod" is
                         : crucial for getting valuable solutions with FDA. As a guideline it
                         : is recommended to start with "FitMethod=MINUIT". When more complex
                         : functions are used where MINUIT does not converge to reasonable
                         : results, the user should switch to non-gradient FitMethods such
                         : as GeneticAlgorithm (GA) or Monte Carlo (MC). It might prove to be
                         : useful to combine GA (or MC) with MINUIT by setting the option
                         : "Converger=MINUIT". GA (MC) will then set the starting parameters
                         : for MINUIT such that the basic quality of GA (MC) of finding global
                         : minima is combined with the efficacy of MINUIT of finding local
                         : minima.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
FitterBase               : <GeneticFitter> Optimisation, please be patient ... (inaccurate progress timing for GA)
                         : Elapsed time: 375 sec                            
FDA_GA                   : Results for parameter fit using "GA" fitter:
                         : -----------------------
                         : Parameter:  Fit result:
                         : -----------------------
                         :    Par(0):    0.275034
                         :    Par(1):     2.86206
                         :    Par(2):     4.20711
                         :    Par(3):    -4.17014
                         :    Par(4):    -8.77152
                         : -----------------------
                         : Discriminator expression: "(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3"
                         : Value of estimator at minimum: 0.357929
                         : Elapsed time for training with 450000 events: 388 sec         
FDA_GA                   : [dataset] : Evaluation of FDA_GA on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.0929 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_FDA_GA.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_FDA_GA.class.C
Factory                  : Training finished
                         : 
Factory                  : Train method: MLPBNN for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ MLPBNN ] :
                         : 
                         : --- Short description:
                         : 
                         : The MLP artificial neural network (ANN) is a traditional feed-
                         : forward multilayer perceptron implementation. The MLP has a user-
                         : defined hidden layer architecture, while the number of input (output)
                         : nodes is determined by the input variables (output classes, i.e., 
                         : signal and one background). 
                         : 
                         : --- Performance optimisation:
                         : 
                         : Neural networks are stable and performing for a large variety of 
                         : linear and non-linear classification problems. However, in contrast
                         : to (e.g.) boosted decision trees, the user is advised to reduce the 
                         : number of input variables that have only little discrimination power. 
                         : 
                         : In the tests we have carried out so far, the MLP and ROOT networks
                         : (TMlpANN, interfaced via TMVA) performed equally well, with however
                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural 
                         : net (CFMlpANN) exhibited worse classification performance in these
                         : tests, which is partly due to the slow convergence of its training
                         : (at least 10k training cycles are required to achieve approximately
                         : competitive results).
                         : 
                         : Overtraining: only the TMlpANN performs an explicit separation of the
                         : full training sample into independent training and validation samples.
                         : We have found that in most high-energy physics applications the 
                         : available degrees of freedom (training events) are sufficient to 
                         : constrain the weights of the relatively simple architectures required
                         : to achieve good performance. Hence no overtraining should occur, and 
                         : the use of validation samples would only reduce the available training
                         : information. However, if the performance on the training sample is 
                         : found to be significantly better than the one found with the inde-
                         : pendent test sample, caution is needed. The results for these samples 
                         : are printed to standard output at the end of each training job.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : The hidden layer architecture for all ANNs is defined by the option
                         : "HiddenLayers=N+1,N,...", where here the first hidden layer has N+1
                         : neurons and the second N neurons (and so on), and where N is the number  
                         : of input variables. Excessive numbers of hidden layers should be avoided,
                         : in favour of more neurons in the first hidden layer.
                         : 
                         : The number of cycles should be above 500. As said, if the number of
                         : adjustable weights is small compared to the training sample size,
                         : using a large number of training samples should not lead to overtraining.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:   -0.50290    0.29329   [    -1.0000     1.0000 ]
                         :     tau2:   -0.62354    0.21478   [    -1.0000     1.0000 ]
                         :     tau3:   -0.61587    0.20225   [    -1.0000     1.0000 ]
                         :     tau4:   -0.62966    0.18565   [    -1.0000     1.0000 ]
                         : -----------------------------------------------------------
                         : Training Network
                         : 
                         : Finalizing handling of Regulator terms, trainE=0.847549 testE=0.8445520.8475/0.8446/59]   
                         : Done with handling of Regulator terms
                         : Elapsed time for training with 450000 events: 305 sec         
MLPBNN                   : [dataset] : Evaluation of MLPBNN on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.432 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_MLPBNN.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_MLPBNN.class.C
                         : Write special histos to file: TMVA.root:/dataset/Method_MLP/MLPBNN
Factory                  : Training finished
                         : 
Factory                  : Train method: DNN_CPU for Classification
                         : 
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:   -0.50290    0.29329   [    -1.0000     1.0000 ]
                         :     tau2:   -0.62354    0.21478   [    -1.0000     1.0000 ]
                         :     tau3:   -0.61587    0.20225   [    -1.0000     1.0000 ]
                         :     tau4:   -0.62966    0.18565   [    -1.0000     1.0000 ]
                         : -----------------------------------------------------------
                         : Start of deep neural network training on CPU using MT,  nthreads = 1
                         : 
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:   -0.50290    0.29329   [    -1.0000     1.0000 ]
                         :     tau2:   -0.62354    0.21478   [    -1.0000     1.0000 ]
                         :     tau3:   -0.61587    0.20225   [    -1.0000     1.0000 ]
                         :     tau4:   -0.62966    0.18565   [    -1.0000     1.0000 ]
                         : -----------------------------------------------------------
                         : *****   Deep Learning Network *****
DEEP NEURAL NETWORK:   Depth = 4  Input = ( 1, 1, 4 )  Batch size = 100  Loss function = C
	Layer 0	 DENSE Layer: 	 ( Input =     4 , Width =   128 ) 	Output = (  1 ,   100 ,   128 ) 	 Activation Function = Tanh
	Layer 1	 DENSE Layer: 	 ( Input =   128 , Width =   128 ) 	Output = (  1 ,   100 ,   128 ) 	 Activation Function = Tanh	 Dropout prob. = 0.5
	Layer 2	 DENSE Layer: 	 ( Input =   128 , Width =   128 ) 	Output = (  1 ,   100 ,   128 ) 	 Activation Function = Tanh	 Dropout prob. = 0.5
	Layer 3	 DENSE Layer: 	 ( Input =   128 , Width =     1 ) 	Output = (  1 ,   100 ,     1 ) 	 Activation Function = Identity	 Dropout prob. = 0.5
                         : Using 360000 events for training and 90000 for testing
                         : Compute initial loss  on the validation data 
                         : Training phase 1 of 1:  Optimizer ADAM (beta1=0.9,beta2=0.999,eps=1e-07) Learning rate = 0.01 regularization 0 minimum error = 0.690554
                         : --------------------------------------------------------------
                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps
                         : --------------------------------------------------------------
                         :    Start epoch iteration ...
                         :          1 Minimum Test error found - save the configuration 
                         :          1 |     0.472465    0.435025     26.2893     2.08425     14872.9           0
                         :          2 |     0.462777    0.436787     26.6472     2.04225     14631.2           1
                         :          3 Minimum Test error found - save the configuration 
                         :          3 |     0.463482    0.432522     26.3994     2.05024     14784.9           0
                         :          4 Minimum Test error found - save the configuration 
                         :          4 |     0.463339    0.428383     26.1012     2.02385     14951.8           0
                         :          5 |     0.462003     0.44064     25.7727     1.97656     15128.5           1
                         :          6 |     0.462853    0.439072     25.6279     1.96229       15212           2
                         :          7 |     0.462271    0.428482     25.4205     1.95647     15342.6           3
                         :          8 |     0.462907    0.438416     25.3188     1.97765     15423.4           4
                         :          9 |     0.462432    0.439669     25.2779     1.94501     15428.8           5
                         :         10 |     0.461708    0.429402     25.2524     1.98374     15471.4           6
                         :         11 Minimum Test error found - save the configuration 
                         :         11 |     0.462365    0.427991     25.2154      1.9373     15465.2           0
                         :         12 |     0.461053    0.436625     25.0764     1.97267     15581.9           1
                         :         13 |     0.461447    0.439819     24.9682     1.94977     15639.6           2
                         :         14 |     0.461336    0.433076     24.9273     1.92462     15650.4           3
                         :         15 |     0.461018    0.443939     24.9008     1.94087     15679.5           4
                         :         16 |      0.46061     0.43797     24.8922     1.96145     15699.5           5
                         :         17 |     0.460205    0.435878     25.2652     1.95269     15442.3           6
                         :         18 |     0.459946    0.437202     25.1072     1.95129     15546.8           7
                         :         19 Minimum Test error found - save the configuration 
                         :         19 |      0.46027    0.427527     24.8898      1.9472     15691.3           0
                         :         20 Minimum Test error found - save the configuration 
                         :         20 |     0.459219    0.426871     24.8326     1.95037     15732.7           0
                         :         21 Minimum Test error found - save the configuration 
                         :         21 |     0.459673    0.424666     24.8749     1.94997     15703.4           0
                         :         22 |       0.4609     0.43812     24.7458     1.94079       15786           1
                         :         23 |     0.459286    0.432094     24.7161     1.90708     15783.2           2
                         :         24 |     0.461439    0.435227     24.8068     1.95513     15753.8           3
                         :         25 |     0.459363    0.429515      24.688     1.91055     15805.1           4
                         :         26 |     0.460269    0.426706      24.703      1.9507     15822.6           5
                         :         27 Minimum Test error found - save the configuration 
                         :         27 |     0.459178     0.42451       24.86      1.9751     15730.9           0
                         :         28 |     0.458189    0.433755     25.5459     1.96867       15269           1
                         :         29 |     0.461606    0.425057     25.8063     2.03425     15143.8           2
                         :         30 |     0.462532    0.444043     25.4073     1.96709     15358.2           3
                         :         31 |     0.460435    0.434648     24.7861     1.95802       15770           4
                         :         32 |     0.458324    0.437504     24.8898     1.94756     15691.6           5
                         :         33 |      0.46018    0.426495     24.9123     1.96497     15688.1           6
                         :         34 |     0.459047    0.448314     24.8902     1.95697     15697.7           7
                         :         35 |     0.461352    0.441313     25.0553     1.93794     15572.7           8
                         :         36 |     0.461858    0.429182     24.5972     1.90247     15862.7           9
                         :         37 |     0.459449    0.425066     24.7293     1.93999     15796.8          10
                         :         38 |     0.460031    0.427304     24.8508     2.02567     15772.1          11
                         :         39 |     0.460243    0.427806     25.0447     1.98197     15609.6          12
                         :         40 |     0.458904    0.433737     24.9605     1.91667     15622.4          13
                         :         41 |     0.458648    0.450837     24.9313     1.96141     15672.7          14
                         :         42 |     0.458969    0.426875     25.1212     1.96547     15546.9          15
                         :         43 Minimum Test error found - save the configuration 
                         :         43 |     0.458966    0.422093     24.7777     1.95903     15776.6           0
                         :         44 |     0.459131    0.423768     24.7839     1.93945     15758.7           1
                         :         45 |     0.460529    0.432949     25.0977     1.94312     15547.7           2
                         :         46 |     0.462602    0.433755     24.9357     1.91697     15639.4           3
                         :         47 |     0.459455    0.439545     24.9541     1.96881     15662.2           4
                         :         48 |     0.462055     0.43614     24.7593     1.93377     15771.8           5
                         :         49 |     0.459108    0.425534     24.9912     1.93446     15613.7           6
                         :         50 |     0.460174    0.472493     24.6543     1.94411     15851.9           7
                         :         51 |     0.461686    0.426804     24.5895     1.88763     15857.7           8
                         :         52 |     0.461193    0.451948     24.6006     1.92881     15878.7           9
                         :         53 |     0.459881    0.432254     24.5813       1.926     15890.3          10
                         :         54 |     0.459288    0.430339     24.4797     1.89905     15942.8          11
                         :         55 |     0.461189    0.430436     24.5548     1.92616       15909          12
                         :         56 |     0.460898    0.450967     24.4538      1.9184     15974.8          13
                         :         57 |     0.460858    0.442548     24.4271     1.92053     15995.3          14
                         :         58 |     0.461252    0.433841      24.455     1.91029     15968.2          15
                         :         59 |     0.460896    0.425829     24.5277     1.92421     15926.7          16
                         :         60 |     0.459605    0.442679     24.4686     1.92829     15971.4          17
                         :         61 |     0.461065    0.424115     24.3925     1.87829     15989.9          18
                         :         62 |     0.460048    0.431007     24.4178     1.91672     15999.3          19
                         :         63 |     0.459806    0.439177     24.4628     1.91857     15968.6          20
                         :         64 |     0.460104    0.436351     24.4924     1.91474       15945          21
                         : 
                         : Elapsed time for training with 450000 events: 1.6e+03 sec         
                         : Evaluate deep neural network on CPU using batches with size = 100
                         : 
DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 9.62 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_DNN_CPU.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_DNN_CPU.class.C
Factory                  : Training finished
                         : 
Factory                  : Train method: BDT for Classification
                         : 
BDT                      : #events: (reweighted) sig: 225000 bkg: 225000
                         : #events: (unweighted) sig: 225000 bkg: 225000
                         : Training 850 Decision Trees ... patience please
                         : Elapsed time for training with 450000 events: 159 sec         
BDT                      : [dataset] : Evaluation of BDT on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 16 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_BDT.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_BDT.class.C
                         : TMVA.root:/dataset/Method_BDT/BDT
Factory                  : Training finished
                         : 
Factory                  : Train method: RuleFit for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ RuleFit ] :
                         : 
                         : --- Short description:
                         : 
                         : This method uses a collection of so called rules to create a
                         : discriminating scoring function. Each rule consists of a series
                         : of cuts in parameter space. The ensemble of rules are created
                         : from a forest of decision trees, trained using the training data.
                         : Each node (apart from the root) corresponds to one rule.
                         : The scoring function is then obtained by linearly combining
                         : the rules. A fitting procedure is applied to find the optimum
                         : set of coefficients. The goal is to find a model with few rules
                         : but with a strong discriminating power.
                         : 
                         : --- Performance optimisation:
                         : 
                         : There are two important considerations to make when optimising:
                         : 
                         :   1. Topology of the decision tree forest
                         :   2. Fitting of the coefficients
                         : 
                         : The maximum complexity of the rules is defined by the size of
                         : the trees. Large trees will yield many complex rules and capture
                         : higher order correlations. On the other hand, small trees will
                         : lead to a smaller ensemble with simple rules, only capable of
                         : modeling simple structures.
                         : Several parameters exists for controlling the complexity of the
                         : rule ensemble.
                         : 
                         : The fitting procedure searches for a minimum using a gradient
                         : directed path. Apart from step size and number of steps, the
                         : evolution of the path is defined by a cut-off parameter, tau.
                         : This parameter is unknown and depends on the training data.
                         : A large value will tend to give large weights to a few rules.
                         : Similarly, a small value will lead to a large set of rules
                         : with similar weights.
                         : 
                         : A final point is the model used; rules and/or linear terms.
                         : For a given training sample, the result may improve by adding
                         : linear terms. If best performance is obtained using only linear
                         : terms, it is very likely that the Fisher discriminant would be
                         : a better choice. Ideally the fitting procedure should be able to
                         : make this choice by giving appropriate weights for either terms.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : I.  TUNING OF RULE ENSEMBLE:
                         : 
                         :    ForestType  : Recommended is to use the default "AdaBoost".
                         :    nTrees      : More trees leads to more rules but also slow
                         :                  performance. With too few trees the risk is
                         :                  that the rule ensemble becomes too simple.
                         :    fEventsMin  
                         :    fEventsMax  : With a lower min, more large trees will be generated
                         :                  leading to more complex rules.
                         :                  With a higher max, more small trees will be
                         :                  generated leading to more simple rules.
                         :                  By changing this range, the average complexity
                         :                  of the rule ensemble can be controlled.
                         :    RuleMinDist : By increasing the minimum distance between
                         :                  rules, fewer and more diverse rules will remain.
                         :                  Initially it is a good idea to keep this small
                         :                  or zero and let the fitting do the selection of
                         :                  rules. In order to reduce the ensemble size,
                         :                  the value can then be increased.
                         : 
                         : II. TUNING OF THE FITTING:
                         : 
                         :    GDPathEveFrac : fraction of events in path evaluation
                         :                  Increasing this fraction will improve the path
                         :                  finding. However, a too high value will give few
                         :                  unique events available for error estimation.
                         :                  It is recommended to use the default = 0.5.
                         :    GDTau         : cutoff parameter tau
                         :                  By default this value is set to -1.0.
                         :                  This means that the cut off parameter is
                         :                  automatically estimated. In most cases
                         :                  this should be fine. However, you may want
                         :                  to fix this value if you already know it
                         :                  and want to reduce on training time.
                         :    GDTauPrec     : precision of estimated tau
                         :                  Increase this precision to find a more
                         :                  optimum cut-off parameter.
                         :    GDNStep       : number of steps in path search
                         :                  If the number of steps is too small, then
                         :                  the program will give a warning message.
                         : 
                         : III. WARNING MESSAGES
                         : 
                         : Risk(i+1)>=Risk(i) in path
                         : Chaotic behaviour of risk evolution.
                         :                  The error rate was still decreasing at the end
                         :                  By construction the Risk should always decrease.
                         :                  However, if the training sample is too small or
                         :                  the model is overtrained, such warnings can
                         :                  occur.
                         :                  The warnings can safely be ignored if only a
                         :                  few (<3) occur. If more warnings are generated,
                         :                  the fitting fails.
                         :                  A remedy may be to increase the value
                         :                  GDValidEveFrac to 1.0 (or a larger value).
                         :                  In addition, if GDPathEveFrac is too high
                         :                  the same warnings may occur since the events
                         :                  used for error estimation are also used for
                         :                  path estimation.
                         :                  Another possibility is to modify the model - 
                         :                  See above on tuning the rule ensemble.
                         : 
                         : The error rate was still decreasing at the end of the path
                         :                  Too few steps in path! Increase GDNSteps.
                         : 
                         : Reached minimum early in the search
                         :                  Minimum was found early in the fitting. This
                         :                  may indicate that the used step size GDStep.
                         :                  was too large. Reduce it and rerun.
                         :                  If the results still are not OK, modify the
                         :                  model either by modifying the rule ensemble
                         :                  or add/remove linear terms
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
RuleFit                  : -------------------RULE ENSEMBLE SUMMARY------------------------
                         : Tree training method               : AdaBoost
                         : Number of events per tree          : 450000
                         : Number of trees                    : 20
                         : Number of generated rules          : 218
                         : Idem, after cleanup                : 67
                         : Average number of cuts per rule    :     2.99
                         : Spread in number of cuts per rules :     1.27
                         : ----------------------------------------------------------------
                         : 
                         : GD path scan - the scan stops when the max num. of steps is reached or a min is found
                         : Estimating the cutoff parameter tau. The estimated time is a pessimistic maximum.
                         : Best path found with tau = 0.0000 after 331 sec      
                         : Fitting model...
<WARNING>                : [>>>>>>>>>>>>>>>] (100%, time left: 0 sec)  
                         : Minimisation elapsed time : 468 sec                      
                         : ----------------------------------------------------------------
                         : Found minimum at step 10000 with error = 0.575387
                         : Reason for ending loop: end of loop reached
                         : ----------------------------------------------------------------
                         : The error rate was still decreasing at the end of the path
                         : Increase number of steps (GDNSteps).
                         : Removed 22 out of a total of 67 rules with importance < 0.001
                         : 
                         : ================================================================
                         :                           M o d e l                             
                         : ================================================================
RuleFit                  : Offset (a0) = -0.956755
                         : ------------------------------------
                         : Linear model (weights unnormalised)
                         : ------------------------------------
                         : Variable :     Weights : Importance
                         : ------------------------------------
                         :     tau1 :   5.451e-01 :  0.131
                         :     tau2 :   1.206e+00 :  0.140
                         :     tau3 :  -1.084e+00 :  0.075
                         :     tau4 :  -2.746e+00 :  0.144
                         : ------------------------------------
                         : Number of rules = 45
                         : Printing the first 10 rules, ordered in importance.
                         : Rule    1 : Importance  = 1.0000
                         :             Cut  1 :     0.0968 < tau1 <      0.254
                         :             Cut  2 :              tau4 <     0.0658
                         : Rule    2 : Importance  = 0.5134
                         :             Cut  1 :     0.0621 < tau1             
                         : Rule    3 : Importance  = 0.4735
                         :             Cut  1 :      0.124 < tau1             
                         :             Cut  2 :      0.105 < tau2             
                         :             Cut  3 :     0.0528 < tau3             
                         : Rule    4 : Importance  = 0.4272
                         :             Cut  1 :              tau1 <      0.175
                         :             Cut  2 :      0.044 < tau4             
                         : Rule    5 : Importance  = 0.3475
                         :             Cut  1 :              tau3 <     0.0531
                         : Rule    6 : Importance  = 0.3366
                         :             Cut  1 :      0.124 < tau1             
                         :             Cut  2 :              tau2 <      0.105
                         : Rule    7 : Importance  = 0.3288
                         :             Cut  1 :              tau2 <      0.125
                         : Rule    8 : Importance  = 0.2629
                         :             Cut  1 :     0.0549 < tau2             
                         :             Cut  2 :              tau4 <     0.0768
                         : Rule    9 : Importance  = 0.2570
                         :             Cut  1 :              tau1 <      0.124
                         :             Cut  2 :              tau3 <     0.0339
                         : Rule   10 : Importance  = 0.2348
                         :             Cut  1 :     0.0968 < tau1 <      0.254
                         :             Cut  2 :     0.0282 < tau4 <     0.0658
                         : Skipping the next 35 rules
                         : ================================================================
                         : 
<WARNING>                : No input variable directory found - BUG?
                         : Elapsed time for training with 450000 events: 813 sec         
RuleFit                  : [dataset] : Evaluation of RuleFit on training sample (450000 events)
                         : Elapsed time for evaluation of 450000 events: 0.267 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_RuleFit.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_RuleFit.class.C
                         : TMVA.root:/dataset/Method_RuleFit/RuleFit
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
Likelihood               : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable  : Delta Separation
                         : -----------------------------------
                         :    1 : tau4      : 7.115e-03
                         :    2 : tau3      : 1.200e-03
                         :    3 : tau2      : -2.071e-03
                         :    4 : tau1      : -5.348e-03
                         : -----------------------------------
LikelihoodPCA            : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable  : Delta Separation
                         : -----------------------------------
                         :    1 : tau3      : 5.122e-02
                         :    2 : tau2      : 4.902e-02
                         :    3 : tau1      : 3.982e-02
                         :    4 : tau4      : 4.853e-03
                         : -----------------------------------
                         : No variable ranking supplied by classifier: KNN
LD                       : Ranking result (top variable is best ranked)
                         : -------------------------------
                         : Rank : Variable  : Discr. power
                         : -------------------------------
                         :    1 : tau4      : 1.324e+01
                         :    2 : tau2      : 5.260e+00
                         :    3 : tau1      : 2.144e+00
                         :    4 : tau3      : 3.558e-01
                         : -------------------------------
                         : No variable ranking supplied by classifier: FDA_GA
MLPBNN                   : Ranking result (top variable is best ranked)
                         : -----------------------------
                         : Rank : Variable  : Importance
                         : -----------------------------
                         :    1 : tau1      : 1.233e+01
                         :    2 : tau2      : 1.007e+01
                         :    3 : tau4      : 7.921e+00
                         :    4 : tau3      : 6.410e+00
                         : -----------------------------
                         : No variable ranking supplied by classifier: DNN_CPU
BDT                      : Ranking result (top variable is best ranked)
                         : --------------------------------------
                         : Rank : Variable  : Variable Importance
                         : --------------------------------------
                         :    1 : tau1      : 3.317e-01
                         :    2 : tau4      : 2.461e-01
                         :    3 : tau2      : 2.425e-01
                         :    4 : tau3      : 1.797e-01
                         : --------------------------------------
RuleFit                  : Ranking result (top variable is best ranked)
                         : -----------------------------
                         : Rank : Variable  : Importance
                         : -----------------------------
                         :    1 : tau1      : 1.000e+00
                         :    2 : tau4      : 7.691e-01
                         :    3 : tau2      : 5.557e-01
                         :    4 : tau3      : 3.392e-01
                         : -----------------------------
TH1.Print Name  = TrainingHistory_DNN_CPU_trainingError, Entries= 0, Total sum= 29.4934
TH1.Print Name  = TrainingHistory_DNN_CPU_valError, Entries= 0, Total sum= 27.8026
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
                         : Reading weight file: dataset/weights/TMVAClassification_Likelihood.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_LikelihoodPCA.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_KNN.weights.xml
                         : Creating kd-tree with 450000 events
                         : Computing scale factor for 1d distributions: (ifrac, bottom, top) = (80%, 10%, 90%)
ModulekNN                : Optimizing tree for 4 variables with 450000 values
                         : <Fill> Class 1 has   225000 events
                         : <Fill> Class 2 has   225000 events
                         : Reading weight file: dataset/weights/TMVAClassification_LD.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_FDA_GA.weights.xml
                         : User-defined formula string       : "(0)+(1)*x0+(2)*x1+(3)*x2+(4)*x3"
                         : TFormula-compatible formula string: "[0]+[1]*[5]+[2]*[6]+[3]*[7]+[4]*[8]"
                         : Reading weight file: dataset/weights/TMVAClassification_MLPBNN.weights.xml
MLPBNN                   : Building Network. 
                         : Initializing weights
                         : Reading weight file: dataset/weights/TMVAClassification_DNN_CPU.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_BDT.weights.xml
                         : Reading weight file: dataset/weights/TMVAClassification_RuleFit.weights.xml
Factory                  : Test all methods
Factory                  : Test method: Likelihood for Classification performance
                         : 
Likelihood               : [dataset] : Evaluation of Likelihood on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.251 sec       
Factory                  : Test method: LikelihoodPCA for Classification performance
                         : 
LikelihoodPCA            : [dataset] : Evaluation of LikelihoodPCA on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.523 sec       
Factory                  : Test method: KNN for Classification performance
                         : 
KNN                      : [dataset] : Evaluation of KNN on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 52.7 sec       
Factory                  : Test method: LD for Classification performance
                         : 
LD                       : [dataset] : Evaluation of LD on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.0854 sec       
                         : Dataset[dataset] : Evaluation of LD on testing sample
Factory                  : Test method: FDA_GA for Classification performance
                         : 
FDA_GA                   : [dataset] : Evaluation of FDA_GA on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.0858 sec       
Factory                  : Test method: MLPBNN for Classification performance
                         : 
MLPBNN                   : [dataset] : Evaluation of MLPBNN on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.447 sec       
Factory                  : Test method: DNN_CPU for Classification performance
                         : 
                         : Evaluate deep neural network on CPU using batches with size = 1000
                         : 
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:   -0.62809    0.28230   [    -1.0000    0.94081 ]
                         :     tau2:   -0.70052    0.18937   [    -1.0000    0.89274 ]
                         :     tau3:   -0.64829    0.20495   [    -1.0000    0.99428 ]
                         :     tau4:   -0.64755    0.20183   [    -1.0000     1.0948 ]
                         : -----------------------------------------------------------
DNN_CPU                  : [dataset] : Evaluation of DNN_CPU on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 9.72 sec       
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [dataset] : Evaluation of BDT on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 14.4 sec       
Factory                  : Test method: RuleFit for Classification performance
                         : 
RuleFit                  : [dataset] : Evaluation of RuleFit on testing sample (497441 events)
                         : Elapsed time for evaluation of 497441 events: 0.3 sec       
Factory                  : Evaluate all methods
Factory                  : Evaluate classifier: Likelihood
                         : 
Likelihood               : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_Likelihood     : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: LikelihoodPCA
                         : 
TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:-0.00012451    0.10311   [   -0.14998    0.64346 ]
                         :     tau2:-9.6250e-05   0.028539   [   -0.20449    0.19531 ]
                         :     tau3: 1.1079e-05  0.0089342   [   -0.15540   0.056083 ]
                         :     tau4:-2.4063e-06  0.0030434   [  -0.056097   0.025912 ]
                         : -----------------------------------------------------------
LikelihoodPCA            : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_LikelihoodPCA  : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:-0.00012451    0.10311   [   -0.14998    0.64346 ]
                         :     tau2:-9.6250e-05   0.028539   [   -0.20449    0.19531 ]
                         :     tau3: 1.1079e-05  0.0089342   [   -0.15540   0.056083 ]
                         :     tau4:-2.4063e-06  0.0030434   [  -0.056097   0.025912 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: KNN
                         : 
KNN                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_KNN            : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: LD
                         : 
LD                       : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
                         : Also filling probability and rarity histograms (on request)...
TFHandler_LD             : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: FDA_GA
                         : 
FDA_GA                   : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_FDA_GA         : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: MLPBNN
                         : 
TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:   -0.62809    0.28230   [    -1.0000    0.94081 ]
                         :     tau2:   -0.70052    0.18937   [    -1.0000    0.89274 ]
                         :     tau3:   -0.64829    0.20495   [    -1.0000    0.99428 ]
                         :     tau4:   -0.64755    0.20183   [    -1.0000     1.0948 ]
                         : -----------------------------------------------------------
MLPBNN                   : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_MLPBNN         : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:   -0.62809    0.28230   [    -1.0000    0.94081 ]
                         :     tau2:   -0.70052    0.18937   [    -1.0000    0.89274 ]
                         :     tau3:   -0.64829    0.20495   [    -1.0000    0.99428 ]
                         :     tau4:   -0.64755    0.20183   [    -1.0000     1.0948 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: DNN_CPU
                         : 
DNN_CPU                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
                         : Evaluate deep neural network on CPU using batches with size = 1000
                         : 
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:   -0.50290    0.29329   [    -1.0000     1.0000 ]
                         :     tau2:   -0.62354    0.21478   [    -1.0000     1.0000 ]
                         :     tau3:   -0.61587    0.20225   [    -1.0000     1.0000 ]
                         :     tau4:   -0.62966    0.18565   [    -1.0000     1.0000 ]
                         : -----------------------------------------------------------
TFHandler_DNN_CPU        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:   -0.62809    0.28230   [    -1.0000    0.94081 ]
                         :     tau2:   -0.70052    0.18937   [    -1.0000    0.89274 ]
                         :     tau3:   -0.64829    0.20495   [    -1.0000    0.99428 ]
                         :     tau4:   -0.64755    0.20183   [    -1.0000     1.0948 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
Factory                  : Evaluate classifier: RuleFit
                         : 
RuleFit                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_RuleFit        : Variable        Mean        RMS   [        Min        Max ]
                         : -----------------------------------------------------------
                         :     tau1:    0.12122   0.092009   [     0.0000    0.63256 ]
                         :     tau2:   0.065479   0.041404   [     0.0000    0.41383 ]
                         :     tau3:   0.049003   0.028556   [     0.0000    0.27786 ]
                         :     tau4:   0.040580   0.023239   [     0.0000    0.24119 ]
                         : -----------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       BDT            : 0.891
                         : dataset       MLPBNN         : 0.887
                         : dataset       DNN_CPU        : 0.887
                         : dataset       KNN            : 0.882
                         : dataset       RuleFit        : 0.874
                         : dataset       LikelihoodPCA  : 0.856
                         : dataset       LD             : 0.852
                         : dataset       FDA_GA         : 0.847
                         : dataset       Likelihood     : 0.743
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              BDT            : 0.267 (0.275)       0.668 (0.668)      0.895 (0.896)
                         : dataset              MLPBNN         : 0.241 (0.241)       0.662 (0.661)      0.890 (0.891)
                         : dataset              DNN_CPU        : 0.248 (0.251)       0.663 (0.663)      0.891 (0.891)
                         : dataset              KNN            : 0.210 (0.325)       0.646 (0.684)      0.888 (0.896)
                         : dataset              RuleFit        : 0.196 (0.201)       0.625 (0.626)      0.869 (0.868)
                         : dataset              LikelihoodPCA  : 0.138 (0.152)       0.592 (0.595)      0.844 (0.845)
                         : dataset              LD             : 0.080 (0.080)       0.552 (0.552)      0.867 (0.867)
                         : dataset              FDA_GA         : 0.052 (0.052)       0.511 (0.514)      0.871 (0.871)
                         : dataset              Likelihood     : 0.020 (0.021)       0.274 (0.272)      0.666 (0.666)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 497441 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 450000 events
                         : 
Factory                  : Thank you for using TMVA!
                         : For citation information, please visit: http://tmva.sf.net/citeTMVA.html
==> Wrote root file: TMVA.root
==> TMVAClassification is done!
--- Launch TMVA GUI to view input file: TMVA.root
=== Note: inactive buttons indicate classifiers that were not trained, ===
===       or functionalities that were not invoked during the training ===

